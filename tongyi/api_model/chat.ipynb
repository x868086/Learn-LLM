{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f18fd1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install -U dashscope"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bc4e09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "_ = load_dotenv(find_dotenv())\n",
    "\n",
    "abc_txt = os.environ.get('SERVER_LESS_KEY')\n",
    "print(abc_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a253038c",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 聊天\n",
    "import os\n",
    "import dashscope\n",
    "\n",
    "message = [\n",
    "    {\"role\":\"system\", \"content\": \"You are a helpful assistant.\"},\n",
    "    {\"role\":\"user\", \"content\": \"介绍一下你自己\"}\n",
    "]\n",
    "response = dashscope.Generation.call(\n",
    "    api_key = abc_txt,\n",
    "    model=\"qwen-plus\",\n",
    "    messages=message,\n",
    "    result_format=\"message\",\n",
    "    stream=True\n",
    ")\n",
    "\n",
    "# print(list(response))\n",
    "\n",
    "for chunk in response:\n",
    "    print(chunk)\n",
    "    if chunk.get(\"status_code\") == 200:\n",
    "        # content = chunk.get(\"output\").get(\"choices\")[0].get(\"message\")\n",
    "        # content = chunk.output.choices[0].message\n",
    "        content = chunk['output']['choices'][0]['message']\n",
    "        print(content, end=\"\", flush=True)\n",
    "    else:\n",
    "    # 如果出现错误，打印错误信息\n",
    "        print(f\"错误码：{chunk.code}\")\n",
    "        print(f\"错误信息：{chunk.message}\")\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "863306db",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 多轮对话\n",
    "\n",
    "import os\n",
    "import dashscope\n",
    "from dashscope import Generation\n",
    "\n",
    "api_key = os.getenv(\"DASHSCOPE_API_KEY\")\n",
    "\n",
    "def get_response(input):\n",
    "    response = Generation.call(\n",
    "        api_key = api_key,\n",
    "        model = \"qwen-plus\",\n",
    "        messages = input,\n",
    "        result_format = \"message\"\n",
    "    )\n",
    "    return response\n",
    "\n",
    "chat_messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"\"\"你是一名阿里云百炼手机商店的店员，你负责给用户推荐手机。手机有两个参数：屏幕尺寸（包括6.1英寸、6.5英寸、6.7英寸）、分辨率（包括2K、4K）。\n",
    "        你一次只能向用户提问一个参数。如果用户提供的信息不全，你需要反问他，让他提供没有提供的参数。如果参数收集完成，你要说：我已了解您的购买意向，请稍等。\"\"\"\n",
    "    }\n",
    "]\n",
    "\n",
    "assitant_message = \"欢迎光临阿里云百炼手机商店，您需要购买什么尺寸的手机呢？\"\n",
    "\n",
    "print(f\"模型输出：{assitant_message} \\n\")\n",
    "\n",
    "while \"我已了解您的购买意向\" not in assitant_message:\n",
    "    user_input = input(\"用户输入：\")\n",
    "    chat_messages.append({\n",
    "        \"role\":\"user\",\n",
    "        \"content\": user_input\n",
    "    })\n",
    "    response = get_response(chat_messages)\n",
    "    assitant_message = response.output.choices[0].message.content\n",
    "    chat_messages.append({\n",
    "        \"role\":\"assistant\",\n",
    "        \"content\": assitant_message\n",
    "    })\n",
    "    print(f\"模型输出：{assitant_message}\")\n",
    "else:\n",
    "    response = get_response(chat_messages)\n",
    "    assitant_message = response.output.choices[0].message.content\n",
    "    print(\"已获取到用户的购买意向\",assitant_message)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14f717c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 流式输出\n",
    "import os\n",
    "from dashscope import Generation\n",
    "api_key = os.getenv('SERVER_LESS_KEY')\n",
    "\n",
    "\n",
    "\n",
    "response = Generation.call(\n",
    "    api_key=api_key,\n",
    "    model='qwen-plus',\n",
    "    messages = [\n",
    "        {\n",
    "            \"role\": \"user\",\n",
    "            \"content\": \"请自我介绍\"\n",
    "        }\n",
    "    ],\n",
    "    result_format = \"message\",\n",
    "    stream = True,\n",
    "    incremental_output=True,\n",
    "\n",
    ")\n",
    "\n",
    "full_result = \"\"\n",
    "for res in response:\n",
    "    result_str = res.output.choices[0].message.content\n",
    "    print(result_str)\n",
    "    full_result += result_str\n",
    "\n",
    "print(full_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb36acd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 思考模式\n",
    "import os\n",
    "from dashscope import Generation\n",
    "\n",
    "api_key = os.getenv('SERVER_LESS_KEY')\n",
    "\n",
    "def chat(prompt):\n",
    "    response = Generation.call(\n",
    "        api_key=api_key,\n",
    "        model='qwen-plus',\n",
    "        messages = prompt,\n",
    "        result_format = 'message',\n",
    "        stream = True,\n",
    "        incremental_output = True,\n",
    "        enable_thinking = True\n",
    "    )\n",
    "    return response \n",
    "\n",
    "\n",
    "reasoning_content = ''\n",
    "answer_content = ''\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"你是谁？\"\n",
    "    }\n",
    "]\n",
    "\n",
    "response = chat(messages)\n",
    "\n",
    "print(\"\\n\"+\"=\" * 20 + \"思考过程\" + \"=\" * 20)\n",
    "\n",
    "if_thinking = True\n",
    "\n",
    "for res in response:\n",
    "    if ((not res.output.choices[0].message.reasoning_content) and (not res.output.choices[0].message.content)):\n",
    "        pass\n",
    "    else: \n",
    "        if(res.output.choices[0].message.reasoning_content and (not res.output.choices[0].message.content)):\n",
    "            print(res.output.choices[0].message.reasoning_content, end=\"\",flush=True)\n",
    "            reasoning_content += res.output.choices[0].message.reasoning_content\n",
    "\n",
    "            if_thinking = False # 结束思考标记\n",
    "\n",
    "        elif(res.output.choices[0].message.content):\n",
    "\n",
    "            # 在非思考模式标记下，输出一次完整回复\n",
    "            if not if_thinking:\n",
    "                print(\"\\n\" + \"=\" * 20 + \"完整回复\" + \"=\" * 20)\n",
    "                # 将思考模式标记切换成 True\n",
    "                if_thinking = True\n",
    "                # 输出回复内容\n",
    "            print(res.output.choices[0].message.content, end=\"\",flush=True)\n",
    "            answer_content += res.output.choices[0].message.content\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c2bba56",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 开启搜索模式\n",
    "\n",
    "import os\n",
    "from dashscope import Generation\n",
    "\n",
    "api_key = os.getenv('SERVER_LESS_KEY')\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"2025年6月，在“午夜之锤”行动中美国出动了几架B2轰炸机？\"\n",
    "    }\n",
    "]\n",
    "\n",
    "def chat(prompt):\n",
    "    response = Generation.call(\n",
    "        api_key=api_key,\n",
    "        model = 'qwen-plus',\n",
    "        messages = prompt,\n",
    "        result_format = 'message',\n",
    "        stream = True,\n",
    "        enable_thinking = True,\n",
    "        incremental_output = True,\n",
    "        enable_search = True, # 开启联网搜索\n",
    "        search_options = {\n",
    "            \"forced_search\": True, # 强制开启联网搜索\n",
    "            \"enable_source\": True, # 使返回结果包含搜索来源的信息，OpenAI 兼容方式暂不支持返回\n",
    "            \"enable_citation\": True, # 开启角标标注功能\n",
    "            \"citation_format\": \"[ref_<number>]\", # 角标形式为[ref_i]\n",
    "            \"search_strategy\": \"pro\" # 模型将搜索10条互联网信息\n",
    "        }\n",
    "    )\n",
    "    return response\n",
    "\n",
    "\n",
    "reasoning_content = \"\"\n",
    "answer_content = \"\"\n",
    "\n",
    "is_first_res = True\n",
    "\n",
    "is_reasoning = True\n",
    "\n",
    "\n",
    "print(\"\\n\" + \"=\"*20 + \"搜索信息\" + \"=\"*20)\n",
    "\n",
    "response = chat(messages)\n",
    "\n",
    "for res in response:\n",
    "    # 判断是否为第一个chunk，便于打印搜索信息\n",
    "    if is_first_res:\n",
    "        search_content = res.output.search_info['search_results']\n",
    "        is_first_res = False\n",
    "        for info in search_content:\n",
    "            print(f\"{info['index']}. 来源：{info['site_name']}, {info['title']}, 链接：{info['url']}\")\n",
    "    \n",
    "    # 输出思考过程，首先判断当前message.reasoning_content中是否有内容，且message.content无内容时为思考模式\n",
    "    if ((res.output.choices[0].message.reasoning_content) and (not res.output.choices[0].message.content)):\n",
    "        # 打印一次正在思考的提示，然后将is_reasoning标记置为False，避免下一次循环时重复打印正在思考的提示\n",
    "        if is_reasoning:\n",
    "            print(\"\\n\"+\"=\" * 20 + \"思考过程\" + \"=\" * 20)\n",
    "            is_reasoning = False\n",
    "        print(res.output.choices[0].message.reasoning_content,end=\"\",flush=True)\n",
    "        reasoning_content += res.output.choices[0].message.reasoning_content\n",
    "    elif (res.output.choices[0].message.content):\n",
    "        # 打印一次正在输出结果的提示，然后将is_reasoning标记置为True，避免下次循环时重复打印正在输出结果的提示\n",
    "        if not is_reasoning:\n",
    "            print(\"\\n\"+\"=\" * 20 + \"输出结果\" + \"=\" * 20)\n",
    "            is_reasoning = True\n",
    "        print(res.output.choices[0].message.content,end=\"\",flush=True)\n",
    "        answer_content += res.output.choices[0].message.content\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d0e7aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 工具调用\n",
    "\n",
    "import os\n",
    "from dashscope import Generation\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import json\n",
    "\n",
    "api_key = os.getenv('SERVER_LESS_KEY')\n",
    "\n",
    "\n",
    "# 自定义获取时间的工具\n",
    "def get_current_time():\n",
    "    time_str = datetime.now().strftime('%Y-%m-%d %H:%M:%S')\n",
    "    print(f\"当前的时间是{time_str}\")\n",
    "    return f\"当前的时间是{time_str}\"\n",
    "\n",
    "\n",
    "# 自定义获取天气的工具\n",
    "def get_local_weather(arguments):\n",
    "    weather_list = ['晴天','多云','雨天']\n",
    "\n",
    "    weather = random.choice(weather_list)\n",
    "\n",
    "    location = arguments['location']\n",
    "\n",
    "    print(f\"{location}的天气是{weather}\")\n",
    "    return f\"{location}的天气是{weather}\"\n",
    "\n",
    "# 测试工具函数\n",
    "# get_local_weather({'location':'上海'})\n",
    "# get_current_time()\n",
    "\n",
    "\n",
    "#创建tools列表\n",
    "\n",
    "tools = [\n",
    "    {\n",
    "        \"type\":\"function\",\n",
    "        \"function\":{\n",
    "            \"name\":\"get_current_time\",\n",
    "            \"description\":\"当需要查询时间的时候，请调用此函数\",\n",
    "            \"parameters\":{}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"type\":\"function\",\n",
    "        \"function\":{\n",
    "            \"name\":\"get_local_weather\",\n",
    "            \"description\":\"当需要查询天气的时候，请调用此函数\",\n",
    "            \"parameters\":{\n",
    "                \"type\":\"object\",\n",
    "                \"properties\":{\n",
    "                    \"location\":{\n",
    "                        \"type\":\"string\",\n",
    "                        \"description\":\"城市或者区县的名称，比如北京市、兴山县等等\"\n",
    "                    }\n",
    "                },\n",
    "                \"required\": [\"location\"],\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\":\"system\",\n",
    "        \"content\":\"你是一个智能助手，专门负责调用各种工具来帮助用户解决问题。请结合工具返回的结果给用户提供相关建议。\"\n",
    "    },\n",
    "    {\n",
    "        \"role\":\"user\",\n",
    "        \"content\":\"上海的天气下雨吗\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 验证创建工具列表\n",
    "# tool_arr = [tool['function']['name'] for tool in tools]\n",
    "# print(tool_arr)\n",
    "\n",
    "def chat(prompt):\n",
    "    response = Generation.call(\n",
    "        api_key = api_key,\n",
    "        model=\"qwen-plus\",\n",
    "        messages=prompt,\n",
    "        tools=tools,\n",
    "        result_format=\"message\",\n",
    "        # stream=True,\n",
    "\n",
    "        # ！！ 开启思考模式，会改变模型函数调用信息的输出结构，模型会先输出思考内容再输出函数调用信息\n",
    "        # enable_thinking = True,\n",
    "\n",
    "        # 并行工具调用，支持输入问题需要调用多次工具\n",
    "        # parallel_tool_calls=True,\n",
    "    )\n",
    "    return response\n",
    "\n",
    "function_mapper = {\n",
    "    \"get_current_time\":get_current_time,\n",
    "    \"get_local_weather\":get_local_weather\n",
    "}\n",
    "\n",
    "\n",
    "def call_with_messages(prompt):\n",
    "    \n",
    "    res = chat(prompt)\n",
    "    msg = res.output.choices[0].message\n",
    "\n",
    "    # 大模型根据输出的tool_calls信息进行总结，必须得将msg加入到messages中\n",
    "    messages.append(msg)\n",
    "\n",
    "\n",
    "    print(json.dumps(res,ensure_ascii=False, indent=4))\n",
    "\n",
    "    answer_content = ''\n",
    "\n",
    "    if 'tool_calls' not in msg:\n",
    "        print(f\"直接回答问题：   {msg.content}\")\n",
    "\n",
    "    elif 'tool_calls' in msg:\n",
    "        fn_name = msg.tool_calls[0][\"function\"][\"name\"]\n",
    "        arguments = json.loads(msg.tool_calls[0][\"function\"][\"arguments\"])\n",
    "\n",
    "\n",
    "        fn = function_mapper[fn_name]\n",
    "        if fn_name == \"get_current_time\":\n",
    "            answer_content = fn()\n",
    "        else:\n",
    "            answer_content = fn(arguments)\n",
    "        \n",
    "        # 大模型根据输出的tool_calls信息进行总结，必须得将函数调用的结果加入到messages中\n",
    "        messages.append({\n",
    "            \"role\":\"tool\",\n",
    "            \"name\":fn_name,\n",
    "            \"content\":answer_content\n",
    "        })\n",
    "\n",
    "call_with_messages(messages)\n",
    "\n",
    "second_res =  chat(messages)\n",
    "second_msg = second_res.output.choices[0].message.content\n",
    "print('\\n'+  '='*20 + '第二轮回答内容' + '='*20)\n",
    "# print(second_res)\n",
    "print(second_msg)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bailian_api",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
